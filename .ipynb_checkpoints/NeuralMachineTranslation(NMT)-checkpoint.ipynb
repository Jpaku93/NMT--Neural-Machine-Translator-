{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "\n",
      "Bad key text.latex.unicode in file C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "# os.getcwd()\n",
    "home = os.getcwd()\n",
    "# % matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences from the text file\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text file\n",
    "os.chdir(home)\n",
    "if not os.path.exists('Translator'):\n",
    "    os.mkdir('Translator')\n",
    "os.chdir('Translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_name = \"nld.txt\"\n",
    "# data = read_text(data_name)\n",
    "# # data\n",
    "# deu_eng = to_lines(data)\n",
    "# deu_eng = array(deu_eng)\n",
    "# len(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Vooruit.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #7915821 (Elsofie)'],\n",
       "       ['Hi.', 'Hoi.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #537889 (Dorenda)'],\n",
       "       ['Hi.', 'HÃ©!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #6117419 (Raizin)'],\n",
       "       ['Hi.', 'Hai!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #6117420 (Raizin)']],\n",
       "      dtype='<U286')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim and preview file\n",
    "deu_eng = deu_eng[:50000,:]\n",
    "deu_eng[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize df for bar plotting\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot bar to identify a suitable sequence length\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 7487\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 10320\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "# chos sequence length is 8\n",
    "deu_length = 8\n",
    "# identify unique words\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a file to pickle tokenizers for prediction\n",
    "\n",
    "\n",
    "# initialize a name for saving\n",
    "name = data_name.split(\".\")[0]\n",
    "\n",
    "# pickle file with the name and pickle tag\n",
    "filename = name+'_eng_tokenizer.pickle'\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# pickle file with the name and pickle tag\n",
    "filename = name+'_deu_tokenizer.pickle'\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(deu_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training sequences\n",
    "trainX = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_sequences(deu_tokenizer, deu_length, train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation sequences\n",
    "testX = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_sequences(deu_tokenizer, deu_length, test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model paramaters\n",
    "model = build_model(eng_vocab_size, deu_vocab_size, eng_length,deu_length, 512)\n",
    "rms = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.7030\n",
      "Epoch 1: val_loss improved from inf to 3.68946, saving model to present_model.h5\n",
      "63/63 [==============================] - 122s 2s/step - loss: 3.7030 - val_loss: 3.6895\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.5173\n",
      "Epoch 2: val_loss improved from 3.68946 to 3.60880, saving model to present_model.h5\n",
      "63/63 [==============================] - 126s 2s/step - loss: 3.5173 - val_loss: 3.6088\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.3789\n",
      "Epoch 3: val_loss improved from 3.60880 to 3.47148, saving model to present_model.h5\n",
      "63/63 [==============================] - 88s 1s/step - loss: 3.3789 - val_loss: 3.4715\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.2373\n",
      "Epoch 4: val_loss improved from 3.47148 to 3.33286, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 3.2373 - val_loss: 3.3329\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.0907\n",
      "Epoch 5: val_loss improved from 3.33286 to 3.24628, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 3.0907 - val_loss: 3.2463\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.9562\n",
      "Epoch 6: val_loss improved from 3.24628 to 3.15816, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 2.9562 - val_loss: 3.1582\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.8382\n",
      "Epoch 7: val_loss improved from 3.15816 to 3.06976, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 2.8382 - val_loss: 3.0698\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.7328\n",
      "Epoch 8: val_loss improved from 3.06976 to 2.97366, saving model to present_model.h5\n",
      "63/63 [==============================] - 88s 1s/step - loss: 2.7328 - val_loss: 2.9737\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.6285\n",
      "Epoch 9: val_loss improved from 2.97366 to 2.90069, saving model to present_model.h5\n",
      "63/63 [==============================] - 94s 1s/step - loss: 2.6285 - val_loss: 2.9007\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.5229\n",
      "Epoch 10: val_loss improved from 2.90069 to 2.83613, saving model to present_model.h5\n",
      "63/63 [==============================] - 92s 1s/step - loss: 2.5229 - val_loss: 2.8361\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.4151\n",
      "Epoch 11: val_loss improved from 2.83613 to 2.80715, saving model to present_model.h5\n",
      "63/63 [==============================] - 91s 1s/step - loss: 2.4151 - val_loss: 2.8071\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3070\n",
      "Epoch 12: val_loss improved from 2.80715 to 2.71647, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 2.3070 - val_loss: 2.7165\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2009\n",
      "Epoch 13: val_loss improved from 2.71647 to 2.62051, saving model to present_model.h5\n",
      "63/63 [==============================] - 87s 1s/step - loss: 2.2009 - val_loss: 2.6205\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0967\n",
      "Epoch 14: val_loss improved from 2.62051 to 2.56781, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 2.0967 - val_loss: 2.5678\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9975\n",
      "Epoch 15: val_loss improved from 2.56781 to 2.51131, saving model to present_model.h5\n",
      "63/63 [==============================] - 84s 1s/step - loss: 1.9975 - val_loss: 2.5113\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9026\n",
      "Epoch 16: val_loss improved from 2.51131 to 2.46971, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 1.9026 - val_loss: 2.4697\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8118\n",
      "Epoch 17: val_loss improved from 2.46971 to 2.43713, saving model to present_model.h5\n",
      "63/63 [==============================] - 86s 1s/step - loss: 1.8118 - val_loss: 2.4371\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7257\n",
      "Epoch 18: val_loss improved from 2.43713 to 2.35953, saving model to present_model.h5\n",
      "63/63 [==============================] - 87s 1s/step - loss: 1.7257 - val_loss: 2.3595\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6385\n",
      "Epoch 19: val_loss improved from 2.35953 to 2.34492, saving model to present_model.h5\n",
      "63/63 [==============================] - 87s 1s/step - loss: 1.6385 - val_loss: 2.3449\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5592\n",
      "Epoch 20: val_loss improved from 2.34492 to 2.28545, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 1.5592 - val_loss: 2.2854\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 21: val_loss improved from 2.28545 to 2.23935, saving model to present_model.h5\n",
      "63/63 [==============================] - 83s 1s/step - loss: 1.4772 - val_loss: 2.2394\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4053\n",
      "Epoch 22: val_loss improved from 2.23935 to 2.21386, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 1.4053 - val_loss: 2.2139\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3300\n",
      "Epoch 23: val_loss improved from 2.21386 to 2.18720, saving model to present_model.h5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 1.3300 - val_loss: 2.1872\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2609\n",
      "Epoch 24: val_loss did not improve from 2.18720\n",
      "63/63 [==============================] - 97s 2s/step - loss: 1.2609 - val_loss: 2.1949\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1914\n",
      "Epoch 25: val_loss improved from 2.18720 to 2.14522, saving model to present_model.h5\n",
      "63/63 [==============================] - 98s 2s/step - loss: 1.1914 - val_loss: 2.1452\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1294\n",
      "Epoch 26: val_loss improved from 2.14522 to 2.12874, saving model to present_model.h5\n",
      "63/63 [==============================] - 98s 2s/step - loss: 1.1294 - val_loss: 2.1287\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0685\n",
      "Epoch 27: val_loss improved from 2.12874 to 2.10671, saving model to present_model.h5\n",
      "63/63 [==============================] - 98s 2s/step - loss: 1.0685 - val_loss: 2.1067\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0089\n",
      "Epoch 28: val_loss did not improve from 2.10671\n",
      "63/63 [==============================] - 97s 2s/step - loss: 1.0089 - val_loss: 2.1085\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9536\n",
      "Epoch 29: val_loss improved from 2.10671 to 2.08645, saving model to present_model.h5\n",
      "63/63 [==============================] - 96s 2s/step - loss: 0.9536 - val_loss: 2.0865\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8994\n",
      "Epoch 30: val_loss improved from 2.08645 to 2.07187, saving model to present_model.h5\n",
      "63/63 [==============================] - 101s 2s/step - loss: 0.8994 - val_loss: 2.0719\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8504\n",
      "Epoch 31: val_loss did not improve from 2.07187\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8504 - val_loss: 2.0763\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8008\n",
      "Epoch 32: val_loss did not improve from 2.07187\n",
      "63/63 [==============================] - 98s 2s/step - loss: 0.8008 - val_loss: 2.1045\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7525\n",
      "Epoch 33: val_loss improved from 2.07187 to 2.05259, saving model to present_model.h5\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.7525 - val_loss: 2.0526\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7124\n",
      "Epoch 34: val_loss improved from 2.05259 to 2.04667, saving model to present_model.h5\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.7124 - val_loss: 2.0467\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6695\n",
      "Epoch 35: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.6695 - val_loss: 2.0532\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6262\n",
      "Epoch 36: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.6262 - val_loss: 2.1162\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5923\n",
      "Epoch 37: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5923 - val_loss: 2.0570\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5547\n",
      "Epoch 38: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.5547 - val_loss: 2.0763\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5207\n",
      "Epoch 39: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.5207 - val_loss: 2.0773\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4897\n",
      "Epoch 40: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.4897 - val_loss: 2.0775\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4582\n",
      "Epoch 41: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 89s 1s/step - loss: 0.4582 - val_loss: 2.1075\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4299\n",
      "Epoch 42: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.4299 - val_loss: 2.0959\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4060\n",
      "Epoch 43: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 115s 2s/step - loss: 0.4060 - val_loss: 2.1103\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3797\n",
      "Epoch 44: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 112s 2s/step - loss: 0.3797 - val_loss: 2.1072\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3561\n",
      "Epoch 45: val_loss did not improve from 2.04667\n",
      "63/63 [==============================] - 113s 2s/step - loss: 0.3561 - val_loss: 2.1118\n",
      "Epoch 46/50\n",
      "59/63 [===========================>..] - ETA: 6s - loss: 0.3346"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-e700568156cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n\u001b[0m\u001b[0;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "os.chdir(home)\n",
    "os.chdir('Translator')\n",
    "if not os.path.exists('Models'):\n",
    "    os.mkdir('Models')\n",
    "os.chdir('Models')\n",
    "name = 'present'\n",
    "filename = name + '_model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=50, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-314735a9fdda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(home)\n",
    "os.chdir('Translator')\n",
    "if not os.path.exists('Models'):\n",
    "    os.mkdir('Models')\n",
    "os.chdir('Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = date + '_ENG_TO_DEU.h5'\n",
    "model.save(filename, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Acer\\\\123 NLP'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testX.shape[0]\n",
    "# testX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 22s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "os.chdir(home)\n",
    "model = load_model('ENG_TO_DEU.h5')\n",
    "# Predict the first item in tmp_x\n",
    "prediction = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a funcction for converting logits into text\n",
    "def logits_to_text(logits, tokenizer):\n",
    "    \n",
    "    # Get index to words\n",
    "    index2word = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    \n",
    "    # Add '<PAD>' at start of index2word\n",
    "    index2word[0] = ''\n",
    "    \n",
    "    # Get the text\n",
    "    text = \" \".join([index2word[prediction] for prediction in np.argmax(logits, 1)])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the logits into text\n",
    "predicted_text = []\n",
    "for i in prediction:\n",
    "    predicted_text.append(logits_to_text(logits = i, tokenizer = deu_tokenizer))\n",
    "# print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,1], 'predicted' : predicted_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ik kon mijn eigen ogen niet geloven.</td>\n",
       "      <td>ik kon mijn ogen niet niet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lach naar het vogeltje.</td>\n",
       "      <td>zeg kaas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hij haat spinnen.</td>\n",
       "      <td>hij verafschuwt spinnen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meende Tom het serieus?</td>\n",
       "      <td>was tom tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waar bent u naar op zoek, meneer?</td>\n",
       "      <td>wat zoek jullie naar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tom en Maria liften.</td>\n",
       "      <td>tom en mary zijn de het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Die kamer wordt als keuken gebruikt.</td>\n",
       "      <td>deze auto is een in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hij is bang dat hij zal sterven.</td>\n",
       "      <td>hij is zeker hij hij te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hij wilde slagen.</td>\n",
       "      <td>hij zou helpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ik woon nog steeds in AustraliÃ«.</td>\n",
       "      <td>ik woon nu steeds in australiÃ«</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 actual                         predicted\n",
       "0  Ik kon mijn eigen ogen niet geloven.      ik kon mijn ogen niet niet  \n",
       "1               Lach naar het vogeltje.                    zeg kaas      \n",
       "2                     Hij haat spinnen.      hij verafschuwt spinnen     \n",
       "3               Meende Tom het serieus?                  was tom tom     \n",
       "4     Waar bent u naar op zoek, meneer?          wat zoek jullie naar    \n",
       "5                  Tom en Maria liften.         tom en mary zijn de het  \n",
       "6  Die kamer wordt als keuken gebruikt.            deze auto is een in   \n",
       "7      Hij is bang dat hij zal sterven.         hij is zeker hij hij te  \n",
       "8                     Hij wilde slagen.               hij zou helpen     \n",
       "9      Ik woon nog steeds in AustraliÃ«.  ik woon nu steeds in australiÃ«  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>Die vind ik leuker.</td>\n",
       "      <td>ik denk dat dat dat een</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>Ik heb de deur van het slot gehaald.</td>\n",
       "      <td>ik heb de deur open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Misschien is Tom niet slaperig.</td>\n",
       "      <td>tom kan niet niet niet niet zijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Ik kan voor mezelf opkomen.</td>\n",
       "      <td>ik kan op op op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>Tom kwam heel laat aan.</td>\n",
       "      <td>tom is bijna bijna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Tom heeft de hele zak opgegeten.</td>\n",
       "      <td>tom at het hele overhemd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>We moeten ons registreren.</td>\n",
       "      <td>we hebben hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>Was het goed?</td>\n",
       "      <td>was het goed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>Je was met Tom aan het flirten.</td>\n",
       "      <td>je was precies tom tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Is dat Tom zijn vrouw?</td>\n",
       "      <td>is dat tom toms dochter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Ik weet dat Tom kleurenblind is.</td>\n",
       "      <td>ik weet dat tom is is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Ik moest het zelf doen.</td>\n",
       "      <td>ik moest het het het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Tom houdt van tuinieren.</td>\n",
       "      <td>tom houdt van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Ze sprak de hele tijd.</td>\n",
       "      <td>ze was het hele hele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Snij alsjeblieft de wortels.</td>\n",
       "      <td>bel alstublieft de kaarsen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    actual                          predicted\n",
       "9985                   Die vind ik leuker.          ik denk dat dat dat een  \n",
       "9986  Ik heb de deur van het slot gehaald.             ik heb de deur open   \n",
       "9987       Misschien is Tom niet slaperig.  tom kan niet niet niet niet zijn \n",
       "9988           Ik kan voor mezelf opkomen.                 ik kan op op op   \n",
       "9989               Tom kwam heel laat aan.             tom is bijna bijna    \n",
       "9990      Tom heeft de hele zak opgegeten.        tom at het hele overhemd   \n",
       "9991            We moeten ons registreren.                 we hebben hen     \n",
       "9992                         Was het goed?                  was het goed     \n",
       "9993       Je was met Tom aan het flirten.          je was precies tom tom   \n",
       "9994                Is dat Tom zijn vrouw?         is dat tom toms dochter   \n",
       "9995      Ik weet dat Tom kleurenblind is.            ik weet dat tom is is  \n",
       "9996               Ik moest het zelf doen.            ik moest het het het   \n",
       "9997              Tom houdt van tuinieren.                 tom houdt van     \n",
       "9998                Ze sprak de hele tijd.            ze was het hele hele   \n",
       "9999          Snij alsjeblieft de wortels.     bel alstublieft de kaarsen    "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>Die vind ik leuker.</td>\n",
       "      <td>ik denk dat dat dat een</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>Ik heb de deur van het slot gehaald.</td>\n",
       "      <td>ik heb de deur open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Misschien is Tom niet slaperig.</td>\n",
       "      <td>tom kan niet niet niet niet zijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Ik kan voor mezelf opkomen.</td>\n",
       "      <td>ik kan op op op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>Tom kwam heel laat aan.</td>\n",
       "      <td>tom is bijna bijna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Tom heeft de hele zak opgegeten.</td>\n",
       "      <td>tom at het hele overhemd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>We moeten ons registreren.</td>\n",
       "      <td>we hebben hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>Was het goed?</td>\n",
       "      <td>was het goed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>Je was met Tom aan het flirten.</td>\n",
       "      <td>je was precies tom tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Is dat Tom zijn vrouw?</td>\n",
       "      <td>is dat tom toms dochter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Ik weet dat Tom kleurenblind is.</td>\n",
       "      <td>ik weet dat tom is is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Ik moest het zelf doen.</td>\n",
       "      <td>ik moest het het het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Tom houdt van tuinieren.</td>\n",
       "      <td>tom houdt van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Ze sprak de hele tijd.</td>\n",
       "      <td>ze was het hele hele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Snij alsjeblieft de wortels.</td>\n",
       "      <td>bel alstublieft de kaarsen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    actual                          predicted\n",
       "9985                   Die vind ik leuker.          ik denk dat dat dat een  \n",
       "9986  Ik heb de deur van het slot gehaald.             ik heb de deur open   \n",
       "9987       Misschien is Tom niet slaperig.  tom kan niet niet niet niet zijn \n",
       "9988           Ik kan voor mezelf opkomen.                 ik kan op op op   \n",
       "9989               Tom kwam heel laat aan.             tom is bijna bijna    \n",
       "9990      Tom heeft de hele zak opgegeten.        tom at het hele overhemd   \n",
       "9991            We moeten ons registreren.                 we hebben hen     \n",
       "9992                         Was het goed?                  was het goed     \n",
       "9993       Je was met Tom aan het flirten.          je was precies tom tom   \n",
       "9994                Is dat Tom zijn vrouw?         is dat tom toms dochter   \n",
       "9995      Ik weet dat Tom kleurenblind is.            ik weet dat tom is is  \n",
       "9996               Ik moest het zelf doen.            ik moest het het het   \n",
       "9997              Tom houdt van tuinieren.                 tom houdt van     \n",
       "9998                Ze sprak de hele tijd.            ze was het hele hele   \n",
       "9999          Snij alsjeblieft de wortels.     bel alstublieft de kaarsen    "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>Ik heb een jonge dochter.</td>\n",
       "      <td>ik heb een een dan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>Ik ben dol op kinderen.</td>\n",
       "      <td>ik hou van kinderen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5142</th>\n",
       "      <td>Dat spreekt vanzelf.</td>\n",
       "      <td>zeker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>Niets vergeten.</td>\n",
       "      <td>vergeet goed niets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>Dit antwoord maakt me boos.</td>\n",
       "      <td>dat maakt me me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9815</th>\n",
       "      <td>De sneeuw smelt.</td>\n",
       "      <td>de sneeuw is aan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>Grijp ze zolang je kunt.</td>\n",
       "      <td>kom het zo van over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>Tom vouwde zijn zakdoek op.</td>\n",
       "      <td>tom heeft zijn zijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>Dit is een grap.</td>\n",
       "      <td>dit is een klein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>Ik hou van kittens.</td>\n",
       "      <td>ik hou van van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8293</th>\n",
       "      <td>Geen bezwaar wat mij betreft.</td>\n",
       "      <td>een liever liever zijn je</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9787</th>\n",
       "      <td>Ik ben er zeker van dat Tom het geweldig zal vinden.</td>\n",
       "      <td>weet zeker dat dat het niet zal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8189</th>\n",
       "      <td>Hoe hebben jullie drie elkaar ontmoet?</td>\n",
       "      <td>hoe heb je de de ontmoet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>Het was niet heel goed.</td>\n",
       "      <td>het was niet erg erg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>Het is tijd om in te pakken.</td>\n",
       "      <td>het is tijd tijd om</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    actual  \\\n",
       "4434                             Ik heb een jonge dochter.   \n",
       "8998                               Ik ben dol op kinderen.   \n",
       "5142                                  Dat spreekt vanzelf.   \n",
       "1776                                       Niets vergeten.   \n",
       "3349                           Dit antwoord maakt me boos.   \n",
       "9815                                      De sneeuw smelt.   \n",
       "5297                              Grijp ze zolang je kunt.   \n",
       "5004                           Tom vouwde zijn zakdoek op.   \n",
       "5219                                      Dit is een grap.   \n",
       "3003                                   Ik hou van kittens.   \n",
       "8293                         Geen bezwaar wat mij betreft.   \n",
       "9787  Ik ben er zeker van dat Tom het geweldig zal vinden.   \n",
       "8189                Hoe hebben jullie drie elkaar ontmoet?   \n",
       "2771                               Het was niet heel goed.   \n",
       "8174                          Het is tijd om in te pakken.   \n",
       "\n",
       "                             predicted  \n",
       "4434             ik heb een een dan     \n",
       "8998           ik hou van kinderen      \n",
       "5142                      zeker         \n",
       "1776           vergeet goed niets       \n",
       "3349               dat maakt me me      \n",
       "9815              de sneeuw is aan      \n",
       "5297            kom het zo van over     \n",
       "5004           tom heeft zijn zijn      \n",
       "5219              dit is een klein      \n",
       "3003                ik hou van van      \n",
       "8293      een liever liever zijn je     \n",
       "9787  weet zeker dat dat het niet zal   \n",
       "8189        hoe heb je de de ontmoet    \n",
       "2771           het was niet erg erg     \n",
       "8174            het is tijd tijd om     "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"It's time to pack up.\", 'Het is tijd om in te pakken.',\n",
       "       'CC-BY 2.0 (France) Attribution: tatoeba.org #7913357 (CK) & #7928755 (MarijnKp)'],\n",
       "      dtype='<U286')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[8174]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'its time to pack up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "querye = query[0].translate(str.maketrans('', '', string.punctuation))\n",
    "encoded_query = encode_sequences(eng_tokenizer, eng_length, querye)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prob = model.predict(encoded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the logits into text\n",
    "predicted_text = []\n",
    "for i in prob:\n",
    "    predicted_text.append(logits_to_text(logits = i, tokenizer = deu_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten\n"
     ]
    }
   ],
   "source": [
    "print(predicted_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : query, 'predicted' : predicted_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>in zit de de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>een</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>its time to pack up</td>\n",
       "      <td>in zit de de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actual  \\\n",
       "0   its time to pack up   \n",
       "1   its time to pack up   \n",
       "2   its time to pack up   \n",
       "3   its time to pack up   \n",
       "4   its time to pack up   \n",
       "5   its time to pack up   \n",
       "6   its time to pack up   \n",
       "7   its time to pack up   \n",
       "8   its time to pack up   \n",
       "9   its time to pack up   \n",
       "10  its time to pack up   \n",
       "11  its time to pack up   \n",
       "12  its time to pack up   \n",
       "13  its time to pack up   \n",
       "14  its time to pack up   \n",
       "15  its time to pack up   \n",
       "16  its time to pack up   \n",
       "17  its time to pack up   \n",
       "18  its time to pack up   \n",
       "\n",
       "                                                         predicted  \n",
       "0   ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten  \n",
       "1                                                                   \n",
       "2                                                                   \n",
       "3                                                                   \n",
       "4                                                                   \n",
       "5   ik dacht hoopte hoopte ongemakkelijk beloofd beloofd verzetten  \n",
       "6                                                                   \n",
       "7                                                                   \n",
       "8                                                                   \n",
       "9                                                                   \n",
       "10                                                                  \n",
       "11                                                                  \n",
       "12                                                in zit de de      \n",
       "13                                                      een         \n",
       "14                                                      het         \n",
       "15                                                                  \n",
       "16                                                                  \n",
       "17                                                                  \n",
       "18                                                in zit de de      "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "couldnt work it out but it seemed to do fine with a data set so with the dataset of notes theat ive made il throw through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
